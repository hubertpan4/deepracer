{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepracer Dev Log\n",
    "[_Congrats Richard U., you've managed to nerd snipe me._](https://xkcd.com/356/)\n",
    "\n",
    "Hi this is a dev log for the _redacted_ 2024 DeepRacer competition.\n",
    "\n",
    "DeepRacer is an AWS platform used to introduce developers to Reinforcement Learning.\n",
    "Basically Reinforcement learning is automated supervised learning in the sense that supervised training data is automatically generated from and fed back into the training process.\n",
    "In the case of DeepRacer, we are training a neural network to race a car through an arbitrary track using video image data.\n",
    "This is done by using a \"reward function\" to \"grade\" the successive \"states\" that occur due to the neural network's actions.\n",
    "\n",
    "For example in the case of DeepRacer, we are given a \"params\" dictionary object that contains information about the car's current state.\n",
    "This information includes data about the position, speed, and orientation of the car; along with information about its position relative to the track (is it on or off the track).\n",
    "As the goal of this project is to get the car to race through the track in the least amount of time possible without going off track or crashing;\n",
    "our reward function should reward states that are associated with fast race completion times higher than slower race times or crashes.\n",
    "\n",
    "Information about the properties supplied by the \"params\" dictionary object can be found [here](https://docs.aws.amazon.com/deepracer/latest/developerguide/deepracer-reward-function-input.html)\n",
    "Sample simple reward functions can be found [here](https://docs.aws.amazon.com/deepracer/latest/developerguide/deepracer-reward-function-examples.html)\n",
    "\n",
    "Other useful information that I have located is that:\n",
    " - We are using a single camera car (the original deep racer)\n",
    " - The camera pulls images at a rate of 15 frames per second\n",
    " - we can use a restricted set of python libraries (math, random, numpy, scipy, shapely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial thoughts\n",
    "Based off of prior experience with racing go karts, the neural net should probably try to get the car to drive racing lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Plan and Tasks:\n",
    "    - [x] read through documentation\n",
    "\n",
    "## Open questions:\n",
    "    - How do we know if the car has flipped in the simulator? (params.is_crashed?)\n",
    "    - How can we detect skidding in the simulator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximal Policy Optimization (PPO) Notes\n",
    "\n",
    "PPO was created by OpenAi in 2017 and appears to be the current standard for Reinforcement Learning.\n",
    "Appears to be an incremental improvement on the standard Gradient Descent method but with \"clipping\".\n",
    "Where \"clipping\" refers to the limiting of policy changes between updates to prevent performance collapse.\n",
    "\n",
    "Resources:\n",
    " - https://huggingface.co/learn/deep-rl-course/unit8/introduction \n",
    " - Arxiv PDF: https://arxiv.org/abs/1707.06347\n",
    " - Open ai docs:\n",
    "    - https://spinningup.openai.com/en/latest/algorithms/ppo.html \n",
    "    - https://openai.com/index/openai-baselines-ppo/ \n",
    " - wiki: https://en.wikipedia.org/wiki/Proximal_policy_optimization\n",
    " - Simulator notes:\n",
    "    - https://openai.com/index/roboschool/ (defunct) see https://github.com/Farama-Foundation/Gymnasium and https://farama.org/projects \n",
    "    - joint simulation\n",
    "        - mujoco\n",
    "            - https://gymnasium.farama.org/environments/mujoco/ \n",
    "            - https://github.com/google-deepmind/mujoco \n",
    "            - https://mujoco.readthedocs.io/en/stable/overview.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepracer notes\n",
    "\n",
    "Utilities to process DeepRacer logs: https://github.com/aws-deepracer-community/deepracer-utils \n",
    " - useful for extracting route information\n",
    "Blog on how to train with Racing Lines:\n",
    " - https://mickqg.github.io/DeepracerBlog/ \n",
    " - https://mickqg.github.io/DeepracerBlog/part2.html\n",
    " - https://github.com/MickQG/deepracer-analysis/blob/master/README.md\n",
    "\n",
    "AWS stuff:\n",
    " - https://github.com/aws-solutions-library-samples/guidance-for-training-an-aws-deepracer-model-using-amazon-sagemaker \n",
    " - https://docs.aws.amazon.com/deepracer/latest/student-userguide/reward-function.html\n",
    " - https://github.com/matrousseau/AWS-Deepracer-Optimal-Path-Generator \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Racing Lines:\n",
    "    - https://www.reddit.com/r/coolguides/comments/vw0k49/ideal_racing_lines/ \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapely\n",
    " - https://shapely.readthedocs.io/en/stable/manual.html \n",
    " - https://pypi.org/project/shapely/ \n",
    " - https://github.com/shapely/shapely\n",
    " \n",
    "Spatial analysis library for python, useful for route manipulation.\n",
    "Additional work in [shapelyExp.ipynb](shapelyExp.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'all_wheels_on_track': True, 'x': 3.0, 'y': 3.0, 'closest_objects': [3, 4], 'closest_waypoints': [0, 1], 'distance_from_center': 0.1, 'is_crashed': False, 'is_left_of_center': True, 'is_offtrack': False, 'is_reversed': False, 'heading': 0.1, 'objects_distance': [0.3, 0.1], 'objects_heading': [0.1, 0.2], 'objects_left_of_center': [True, False], 'objects_location': [], 'objects_speed': [3.0, 5.0], 'progress': 0.1, 'speed': 0.1, 'steering_angle': 0, 'steps': 0, 'track_length': 3, 'track_width': 0.1, 'waypoints': [[0, 0], [0, 2]]}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json \n",
    "\n",
    "params = None \n",
    "with open(\"./params.json\", 'r') as f:\n",
    "    params = json.load(f)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reward function component testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array('d', [10.0, 10.0]), array('d', [0.0, 0.3333333333333333]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import reward_function\n",
    "\n",
    "al = [0,1,2,3,4,5]\n",
    "assert [1, 2, 3, 4, 5, 0, 1] == reward_function.spliceWithLoop(al, 1, 8)\n",
    "params['speed'] = 5\n",
    "params['heading'] = 90\n",
    "params[\"steering_angle\"] = 0\n",
    "params['x'] = 10\n",
    "params['y'] = 0\n",
    "reward_function.get_projected_car_path(params).xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepracer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (AnalysisUtils, DeepRacerLog)\n\u001b[1;32m      3\u001b[0m drl \u001b[38;5;241m=\u001b[39m DeepRacerLog(model_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./deepracerlogs/joes-test-model-42-training_job_ngORYSXKStmsCby370Xdtw_logs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_training_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m training_df \u001b[38;5;241m=\u001b[39m drl\u001b[38;5;241m.\u001b[39mdataframe()\n",
      "File \u001b[0;32m~/dev/python/deepracer/deepracer/logs/log.py:180\u001b[0m, in \u001b[0;36mDeepRacerLog.load_training_trace\u001b[0;34m(self, force, ignore_metadata)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_block_duplicate_load(force)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_metadata:\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_trace_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfh\u001b[38;5;241m.\u001b[39mtraining_simtrace_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath to training-simtrace not configured. Check FileHandler configuration.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/python/deepracer/deepracer/logs/log.py:387\u001b[0m, in \u001b[0;36mDeepRacerLog._parse_trace_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfh\u001b[38;5;241m.\u001b[39mlist_files(check_exist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m                        filterexp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfh\u001b[38;5;241m.\u001b[39mhyperparameters_path)\n\u001b[1;32m    385\u001b[0m model_metadata: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    386\u001b[0m model_metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(TextIOWrapper(\n\u001b[0;32m--> 387\u001b[0m     BytesIO(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_metadata_path\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m    388\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_space \u001b[38;5;241m=\u001b[39m model_metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_space\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agent_and_network \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/dev/python/deepracer/deepracer/logs/handler.py:102\u001b[0m, in \u001b[0;36mFSFileHandler.get_file\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Downloads a given file as byte array.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    A bytes object containing the file.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m bytes_io: BytesIO \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    103\u001b[0m     bytes_io \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "from deepracer.logs import (AnalysisUtils, DeepRacerLog)\n",
    "\n",
    "drl = DeepRacerLog(model_folder='./deepracerlogs/joes-test-model-42-training_job_ngORYSXKStmsCby370Xdtw_logs')\n",
    "drl.load_training_trace()\n",
    "training_df = drl.dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
